报告
背景意义
相关理论
实施方案
实验与结果
总结与展望
实习心得
参考文献

# 背景意义

## SLAM简介
SLAM(Simultaneous Localization and Mapping)是即时定位与地图构建的简称。它的任务是让机器人在陌生的环境中，通过自身传感器的数据建立对周围空间的认识以及对自己位置的估计。其中视觉SLMA便是以摄像头作为主要的传感器。  

## SLAM应用场景
SLAM早起应用于军事领域，如今已经得到广泛使用。  
1、自动巡检的机器人  
小到扫地机器人，大到无人驾驶汽车，任何能够自动执行任务的机器人，都需要其在了解自身周围空间状况与自身位置的情况下规划自己的路径，避免在执行任务的时候与周遭发生直接碰撞，尤其是在面对未知空间，人工无法提前提供规划路径的情况下。  
2、AR技术  
AR是现实增强技术，可以将屏幕信息投射到实体物体上，将投射信息显示在佩戴者的目镜上。这与SLAM的定位和建图的需求不谋而合。AR与SLAM技术结合，可以提高图像显示的精度，同时减少对环境中辅助设备的依赖。  


# 相关理论

## 视觉SLAM框架
经典的视觉SLAM框架包括信息读取，前端视觉里程计，后端(非线性)优化，回环检测与建图。  
整个系统首先要读取传感器信息，对图像进行去畸变，时间戳对其等预处理。  
由前端视觉里程计(简称前端)读取输入的数据，估计相机的位姿，生成局部地图。  
后端(非线性)优化(简称后端)接受前端传入的位姿与地图点信息，对它们进行优化。如果接收到回环检测的信号，则会进行更大范围的优化，得到全局一致的轨迹与地图。  
回环检测判断相机是否到达过先前的位置，防止误差随着时间的累积而无限增大。  
建图则是依据计算得到的轨迹，依据一定需求生成地图。  

## 视觉SLAM分类与算法介绍
基于输入图像的类型，视觉SLAM主要分为单目，双目与RGBD。现在下面介绍部分最新的视觉SLAM算法。  
1.DM-VIO  
属于单目与IMU相结合的类型。其利用延迟边缘化实现一种新的IMU初始化方法，完善地解决了IMU初始化器中正确捕获视觉不确定性的问题，非常优秀地改善了初始化，成功将尺度和IMU变量信息从初始化器传递到了主系统，最终也通过这一系列特别的延迟边缘化工程策略，保持了当尺度估计变化时一致的边缘化先验。  
2.DSOL  
着重研究的图像类型为双目。前端采用优化最小光度误差的直接法，采用逆组合对齐方式进行帧跟踪，将新图像与整个窗口进行跟踪，而不是与最后近一个关键帧进行跟踪，通过并行化系统使得有效利用所有可用计算资源。该算法最大的优势是计算量很小，很适合在功耗受限的移动硬件平台使用。
3.ORB-SLAM3
支持多种模式与相机类型，包括单目，双目，RGBD以及它们与IMU的结合。另外ORB-SLAM3实现多地图系统，基于召回率大大提高的回环检测方法，让系统在重新遇到原先丢失的地方时可以与旧的地图进行融合，提高系统长期运行的鲁棒性。  
4.NICE-SLAM  
输入的图像类型位RGBD，使用层次特征网格来表示场景的几何形状和外观，并结合在不同空间分辨率下预训练的神经隐式解码器的归纳偏差，通过从占用率和彩色解码器输出中得到的渲染后的深度和彩色图像。提高系统对于各种具有挑战性的场景具有实时能力、可扩展性、可预测性以及鲁棒性。  
5.Dynamic-VINS
输入RGBD图像与IMU，结合目标检测和深度信息进行动态特征识别，达到了与语义分割相当的性能，并且将IMU应用于运动预测，进行特征跟踪和运动一致性检查。将动态物体进行区分，可以避免其对于位姿估计产生干扰。

## ORB-SLAM3框架详解  
ORB-SLAM3系统的整体运行逻辑只有三步，启动初始化，传入图像信息，关闭与保存数据。在启动初始化时，先通过构建System类，整个ORB-SLAM都运行在System中。初始化时会配置Tracking，LocalMapping，LoopClosing，Viewer这几个主要线程。  
Tracking是主线程，负责读取输入的数据，提取图像特征点并进行位姿跟踪。在一定条件下创建关键帧，传输给LocalMapping。  
LocalMapping读取Tracking中传入的关键帧信息，提取关键帧中与回环检测相关的词袋信息，对关键帧的位姿和地图点进行局部优化，减小Tracking中的误差与噪声，并将关键帧传输给LoopClosing。  
LoopClosing对于新接受的关键帧，会检测其与其他关键帧是否有共视区，并进行地图融合或回环矫正，在整体上对位姿与地图点进行优化。  
Viewer线程负责对关键帧和地图点的位姿信息进行可视化呈现。  
ORB-SLAM3与ORB-SLAM2的一个优化是增加了Atlas类，即地图存储单元。在Atlas中，将地图分为活跃地图和非活跃地图。活跃地图是当前一直追踪，为丢失的地图。若在Tracking中发生丢失，那么系统会将此时的地图设置为非活跃地图，并开启一个新的活跃地图。如果后续有关键帧与非活跃地图的关键帧具有共视区，则会进行地图融合，将该非活跃地图融合到当前的活跃地图中。多地图的设计提高了前端的鲁棒性和全局定位精度。  


# 项目介绍
目标是什么，项目的起因是什么

用ORB-SLAM进行稠密点云的绘制先前有人研究过，最著名的是高翔博士在ORB-SLAM2中用深度图绘制稠密点云。本次的工作与其有如下不同，本次的追踪定位采用双目相机，使用双目定位估计的位姿数据提供给RGB相机，结合深度图绘制稠密点云。因此需要增加数据的通道数量，改变部分数据流向。同时其使用前端估计的位姿来绘制点云，本次工作尝试用后端优化的位姿来绘制。  



# 实施方案与结果

## 硬件
### OAK-D Pro相机介绍
OAK-D Pro相机拥有双目相机，RGB相机与IMU。其最特殊的功能是内嵌高性能芯片，可以实时计算双目相机输入的图像进而输出深度图。同时搭载点阵投射模块、红外夜视IR模组进行辅助。
### 相机标定
#### 相机内外参介绍
对于针孔相机，其成像原理如图x所示。为了将相机图像上的像素坐标系内的坐标转变为相机坐标系内的坐标，需要获取相机内参，$f_x$，$f_y$，$c_x$，$c_y$。其中$f_x$，$f_y$是相机焦距与像素缩放倍数的乘积，$c_x$，$c_y$是像素原点的平移。由于OAK-D Pro相机输出的图像已经去畸变，所以不需要获得畸变参数。  
而对于多个传感器，则需要获取不同传感器之间的位姿变换矩阵，此为外参。  
#### 相机内外参标定方法
方法一：下载标定盘，相机多角度对标定盘进行拍摄录制数据包，将数据包和标定盘参数一起输送到kalibr中，则会自动计算结果。  
方法二：由于相机型号的特殊性，可以直接通过depthai-ros直接读取相机的相关参数，在终端使用ROS开启相机后，读取相关话题信息即可。  
两种方法的结果与比对：  
| Calibration Method | $f_x$  |	$f_y$ | $c_x$ | $c_y$ |
|:--------:| :---------:|:--------:|:--------:|:--------:|
| Kalibr  | 795.65548135 | 797.15810097 | 624.36307918 | 363.1335077|
| Depthai | 794.714111328125 | 794.704345703125 | 621.559326171875 | 362.4109191894531|  

可见相机内参相差不大，但考虑到厂家标定的精度会更高，所以采用Depthai-ros直接获取。但是部分外参，如左目与RGB相机之间的转移矩阵则需要手动使用Kalibr进行标定。  
#### 外参注意事项
由于相机外参涉及坐标系之间的转换，所以在不同情况下对相机坐标系的定义的明确则尤为重要。  
通过按特定方向移动相机，观察相机的位姿变化，得出ORB-SLAM3中的相机坐标系如图x。依据Kalibr标定结果文档，在Kalibr中相机坐标系如图x。从Kalibr相机坐标系到ORB-SLMA3相机坐标系之间的变化为绕着x轴逆时针旋转90°。记变换矩阵为${T_{sk}}$则  
$$T_{sk}=
 \left[
 \begin{matrix}
   1 & 0 & 0 & 0\\
   0 & 0 &-1 & 0\\
   0 & 1 & 0 & 0\\
   0 & 0 & 0 & 1\\
  \end{matrix}
  \right] 
  $$
同时ORB-SLAM3需求的右目相机到左目相机的变换矩阵，而Kalibr输出的是左目相机到右目相机的变换矩阵，所以其中还需要进行人工变换。  
设Kalibr下左右目的坐标系分别设为l，r。在ORB-SLMA3下左右目的坐标系分别为l'，r'。记在坐标系a下点的坐标为$P_a$，从坐标系a到坐标系b的变换为$T_{ba}$。则有  
$$T_{l'l} = T_{r'r} = T_{sk}$$
$$T_{r'l} = T_{r'r}T_{rl} = T_{r'l'}T_{l'l}$$
得
$$T_{l'r'} = T_{r'l'}^{-1} = T_{sk}T_{rl}^{-1}T_{sk}^{-1}$$
$T_{l'r'}$即为OBR-SLAM3所需的双目外参矩阵。(辅助说明图)
### 深度图
#### 理论视距计算
由于绘制稠密点云需要使用深度图，因此为了获得较好的点云质量需要明确相机深度图的有效视距。  
相机的左右目输入同一时刻的图像，经过去畸变后进行像素比对，获取视差(disparity)，进而输出深度图，最终输出以mm为单位的深度图。  
依据双目相机的成像模型，(图x)，可以推导
$$ D = \frac{fb}{d} \tag{1}$$
其中$D$是深度，$f$是相机焦距，$b$是双目相机基线，$d$是视差。由于图像出现在像素平面，所以视差使用像素作为单位，相应地焦距使用像素单位，即相机内参$f_x$。  
为了保证最小视距具可以覆盖较大的范围，在OAK-D PRO相机中通常取视差的检索范围为95个像素，则深度图的最小有效视距为  
$$D_{min}=\frac{f_xb}{d_{max}}=\frac{800\times75}{95}mm=631.58mm$$
从公式(x)可知，实际像素深度与视距为反比关系，虽然理论上可以计算无穷远处的物体距离，但是当视距越小时，由于视差的误差而导致的深度估计产生的偏差也会增加。为了保证准确性，相机会设置最大视距。  
$$\Delta D= \frac{fb}{d^2}\Delta d$$
依据相机的技术文档[x]，  
$$D_{max}=\frac{b}{2}tan(90^\circ-\frac{HFOV}{w})=\frac{75}{2}\times tan(90^\circ-\frac{80^\circ}{1080})mm=29\times10^3mm$$
其中$HFOV$为相机的视角，$w$为相机成像的像素宽度。  
所以相机深度图的有效深度为0.6m至29m。  
#### 深度图质量的优化
为了优化相机的深度图质量，有以下几个方式进行调整。  
依据双目特征点匹配的深度估计对于对象的纹理具有较高的依赖。OAK-D Pro的红外激光点阵(IR laser dot projector)可以适应纹理较少的平面，其原理是输入红外激光，让双目相机获得更多可以匹配的特征点。  
结论：IR Laser Dot Projector的取值范围为0-1200mA。  
对于与相机平行的平面，在距离 4 米内，红外阵列的优化效果明显，IR Laser Dot Projector 的值在500mA 可以达到较明显的效果。在 4 米之后，即使 IR Laser Dot Projector 的值取到最大 1200mA，红外阵列几乎没有体现出改善效果。  
对于与相机垂直的平面，IR Laser Dot Projector的优化效果不佳，即使取最大值，在1m之外的墙面上出现大量深度空缺。  
(放上实验数据)  
在深度计算的算法方面，相机也拥有参数调整的接口。  
置信度阈值(Confidence Threshold)：在计算生成深度图时，每个像素点都会获得一个置信度值(Confidence Value)，置信度值为0时表示这个点的深度绝对准确，置信度值越大，这个点的深度出错的概率越大。在深度图输出之前，会对图像进行滤波，在此时，会直接对置信度值小于置信度阈值的像素点的深度设置为0。  
左右比对阈值(LR Check Threshold):分别计算从左目投影到右目以及从右目投影到左目的视差，两视差之差的绝对值小于左右比对阈值时，则认为这是有效的匹配点。  
结论：Confidence Threshold 和 LR Check Threshold的取值范围都为0-255。  
Confidence Threshold调低之后，观感上深度图质量确实有提升，但这只是将不确定性的点剔除而已，原先质量较差的平面上的点变为全部空缺，因此才显得质量提升。这只起到筛选作用，对深度图质量的整体提升起不到根本性效果。  
LR Check Threshold 调高之后，理论上生成的匹配点增多，对于深度图的计算有了更多参考数据。而这同时导致了深度图误差的增加，因此对于深度图质量提升不明显。  
(放上实验数据与结论)  

## 软件
### 稠密点云绘制
与以往的工作不同，本次需要四个通道分别读入左目，右目，RGB和深度图像。因此分别在depthai-ROS，ORB-SLAM-ROS和ORB-SLAM内部添加相应的数据流通道。  
在ORB-SLAM内部，数据通过`System::TrackStereoRGBD`函数进入SLAM系统，接着通过`Tracking::GrabImageStereoRGBD`函数进入前端。在前端Tracking类中，原来存放图像的成员`mImGray`新增`mImRGB`，`mImDepth`，来临时存放数据。其中`mImGray`将被作为关键帧的成员，加入到后续的后端以及回环优化中，而`mImRGB`以及`mImDepth`将通过`DensePointCloud::insertKeyFrame`函数传输到DensePointCloud类中，并进行存储，传输时机为每产生一个新关键帧就传输对应的RBG和深度图。  
当后端每完成一次局部的位姿优化且关键帧更新一定数量后，就会调用`DensePointCloud::update_viewer_optimized`函数解开点云绘制窗口的线程锁并修改状态变量`mbUpdateDensePointCloud`，设计此变量的目的是防止重复触发点云更新导致运行出错。接着DensePointCloud线程开始工作，通过Atlas类获取当前活跃地图中的关键帧，并通过Id匹配先前从前端传入的RGB图像和深度图像，进而完成稠密点云绘制。  
（加上框架简图与最终的效果图）
### 双目建图与跟踪
### 创新点
使用双目进行定位，rgbd进行点云绘制（想优势是什么）  
尝试在后端优化位姿之后再绘制点云，以提高精度和点云质量


# 总结与展望

## 总结
(工作完成情况)

## 展望
### 融合IMU数据
OAK-D Pro相机自身搭载IMU，可以加上IMU数据实现视觉惯导IMU。视觉与IMU正好可以形成优势互补。对于静态低速的环境，IMU容易受到噪声与漂移的影响，随着时间的推移误差会不断累积，而视觉可以做到很好的追踪。对于高速移动的场景，视觉输出的图像往往会由于曝光时间，产生模糊，而IMU可以在短时间内获得较为高精度的位移数据。  
该设想实施的难点在于IMU的加入复杂了原来纯视觉的系统运行逻辑。虽然ORB-SLAM3整合了IMU模块，但这也让追踪，建图等判定逻辑更加复杂，在理解与修改上需要下更多功夫。另一个难点是硬件的IMU标定，尤其是IMU与相机的联合标定，既需要给IMU提供足够的加速度，有需要保证摄像头图像的质量。  
总而言之，融合IMU数据是一个有价值的尝试方向。    
### 点云管理
在稠密点云绘制的项目中，点云的数量会随着运行时间的增加而不断提升，导致对内存空间的占用不断增加。  
为了减少点云绘制模块内存占用，可以对点云进行滤波处理。最直接的方法是网格滤波，在划定的一个空间内，只能有一个点，这样可以避免同一个区域点云的冗余。  
另外一个思路是修改目前点云模块内的数据存储。目前点云绘制模块内直接存储与关键帧相匹配的RGB图和深度图。可以在数据输入的时候将其提取为规模更小的矩阵，来减小内存空间的占用。  


# 实习心得

## 1.熟悉Linux环境
了解Linux的基本指令。能够寻找，下载并使用cmake编译开源代码。在编译中遇到报错可以查找资料进行解决，也积累了一些经验。例如第三方库版本冲突时，可以下载一个合适版本的库进行软连接，修改C++标准的版本等等。  
在未来如果设计到相关方面的内容，比如为自己设计的机械系统寻找合适的运行代码，就会有方向进行切入，而不是被畏难情绪阻碍。  

## 2.阅读源代码的经验
一个重要的原则是看源代码需要带着目的去看。因为一个复杂项目的源代码量是巨大的，其中的逻辑关系是复杂的。如果不带着目的看，很容易被细枝末节所困扰，而无法取得理想的效果。这正如企业导师王工所说，着眼于需要解决的问题，基于对基本框架的了解去看代码，以实现想要的效果。经过本次的实习，这的确是高效且容易的思路。  
同时在阅读源代码时，要善用资料与搜索，迅速定位相关功能的核心模块，顺藤摸瓜，由点及面。在读源代码的时候不能只局限于是怎么写的，更要理解为什么这么写，其背后的设计逻辑是什么，因为代码只是将人所设计之物进行实现的一种工具罢了。  

## 3.硬件条件的重要性
此次实习需要结合已有的摄像头，即需要与硬件相结合，那么了解硬件各项参数的设置尤为重要。  
比如对相机坐标系认知不清晰，导致绘制稠密点云时总是出现重影。认识到这一点之后对相机的外参进行修改，点云的质量得到明显提升。  
在深度图方面，一开始也只是实现深度图信息的传输，对于其与RGB图像的匹配，深度图形成相关的模块和参数一无所知。这些是在后续的改进中才慢慢所知。  
对于以上情况，可以从ORB-SLAM3的README文件获取其对于相机参数的需求，通过相机的官方技术文档获取对功能的详细解释。对于各种博客和帖子，往往只能起到个例引导的参考作用，在入门时期可以参考，难以提供体系化信息。  


# 参考文献
https://docs.luxonis.com/software/depthai-components/nodes/stereo_depth/ 相机的技术文档



1、项目背景：介绍我们为什么做这个项目，这个项目的具体需求是什么，我们要解决哪些难题；  
2、研究现状：别人有没有做过类似的项目，大家都做到什么程度了；或者别人有没有研究过这个项目相关的关键技术；  
3、具体实施：介绍个人/小组在这个项目上做了哪些工作，实现得怎么样，是否相比前人有所创新或突破；  
4、实验及结果：关于这个项目，做了哪些实验，实验结果如何，若有时间改进，又做了哪几方面的改进，效果怎么样  
5、总结与展望：总结我们这个项目的所有工作量及完成情况，展望就是哪些完成得不足，以后还可以从哪些地方进行改进。
